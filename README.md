# [ICLR2024] Multi-Scale Representations by Varying Window Attention for Semantic Segmentation

<!-- [[`Code`](https://github.com/yan-hao-tian/lawin/blob/70903a10403d4d8b87b0a2fe39a7cf045cf5a476/mask_former/modeling/heads/pixel_decoder.py#L196)] -->

ðŸ”¥ðŸ”¥ðŸ”¥ [ICLR2024 Poster](https://openreview.net/forum?id=lAhWGOkpSR) ðŸ”¥ðŸ”¥ðŸ”¥

[`arxiv`](https://arxiv.org/abs/2404.16573)

[`HuggingFace`](https://huggingface.co/yan-hao-tian)ðŸ¤—


## Running VW
[VW-Swin/ConvNeXt](mmsegmentation-custom)

[VW-MaskFormer](MaskFormer)

[VW-Mask2Former](Mask2Former)


## <a name="CitingMaskFormer"></a>Citing VW

<!-- If you use VWA or VWFormer in your research or wish to refer to the baseline results published in the [Model Zoo]((#ModelZoo)), please use the following BibTeX entry. -->

```BibTeX
@inproceedings{yan2023multi,
  title={Multi-Scale Representations by Varing Window Attention for Semantic Segmentation},
  author={Yan, Haotian and Wu, Ming and Zhang, Chuang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
```

